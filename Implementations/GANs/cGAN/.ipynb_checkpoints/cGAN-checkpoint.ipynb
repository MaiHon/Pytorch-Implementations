{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as tfms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = dsets.FashionMNIST(\n",
    "#     root='./data/', \n",
    "#     train=True, \n",
    "#     transform=tfms.Compose([\n",
    "#         tfms.ToTensor(),\n",
    "#         tfms.Normalize([0.5,], [0.5,])\n",
    "#     ]),\n",
    "#     download=True\n",
    "# )\n",
    "trainset = dsets.MNIST(\n",
    "    root='./data/', \n",
    "    train=True, \n",
    "    transform=tfms.Compose([\n",
    "        tfms.ToTensor(),\n",
    "        tfms.Normalize([0.5,], [0.5,])\n",
    "    ]),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset = trainset,\n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(110, 256),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([z, c], 1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(794, 1024),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, label):\n",
    "        c = self.embed(label)\n",
    "        x = torch.cat([x, c], dim=1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to(device)\n",
    "G = Generator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "d_optim = optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optim = optim.Adam(G.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "Layer(type)                       ||        Kernel Shape         Output Shape         Param #\n",
      "==============================================================================================\n",
      "Discriminator Inputs              ||                   -            [64, 784]               -\n",
      "                                  ||                   -                 [64]               -\n",
      "                                  ||                                                         \n",
      "01> Discriminator-Embedding       ||            [10, 10]             [64, 10]             100\n",
      "02> Discriminator-Model-Linear    ||         [794, 1024]           [64, 1024]         814,080\n",
      "03> Discriminator-Model-LeakyReLU ||                   -           [64, 1024]               0\n",
      "04> Discriminator-Model-Dropout   ||                   -           [64, 1024]               0\n",
      "05> Discriminator-Model-Linear    ||         [1024, 512]            [64, 512]         524,800\n",
      "06> Discriminator-Model-LeakyReLU ||                   -            [64, 512]               0\n",
      "07> Discriminator-Model-Dropout   ||                   -            [64, 512]               0\n",
      "08> Discriminator-Model-Linear    ||          [512, 256]            [64, 256]         131,328\n",
      "09> Discriminator-Model-LeakyReLU ||                   -            [64, 256]               0\n",
      "10> Discriminator-Model-Dropout   ||                   -            [64, 256]               0\n",
      "11> Discriminator-Model-Linear    ||            [256, 1]              [64, 1]             257\n",
      "12> Discriminator-Model-Sigmoid   ||                   -              [64, 1]               0\n",
      "==============================================================================================\n",
      "Total params: 1,470,565\n",
      "Trainable params: 1,470,565\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 2.63\n",
      "Params size (MB): 5.61\n",
      "Estimated Total Size (MB): 8.43\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchsummaryM import summary\n",
    "\n",
    "test_z = torch.zeros((64, 784)).float().to(device)\n",
    "test_label = torch.zeros((64, )).long().to(device)\n",
    "\n",
    "d = summary(D, test_z, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer(type)                   ||        Kernel Shape         Output Shape         Param #\n",
      "==========================================================================================\n",
      "Generator Inputs              ||                   -            [64, 100]               -\n",
      "                              ||                   -                 [64]               -\n",
      "                              ||                                                         \n",
      "01> Generator-Embedding       ||            [10, 10]             [64, 10]             100\n",
      "02> Generator-Model-Linear    ||          [110, 256]            [64, 256]          28,416\n",
      "03> Generator-Model-LeakyReLU ||                   -            [64, 256]               0\n",
      "04> Generator-Model-Linear    ||          [256, 512]            [64, 512]         131,584\n",
      "05> Generator-Model-LeakyReLU ||                   -            [64, 512]               0\n",
      "06> Generator-Model-Linear    ||         [512, 1024]           [64, 1024]         525,312\n",
      "07> Generator-Model-LeakyReLU ||                   -           [64, 1024]               0\n",
      "08> Generator-Model-Linear    ||         [1024, 784]            [64, 784]         803,600\n",
      "09> Generator-Model-Tanh      ||                   -            [64, 784]               0\n",
      "==========================================================================================\n",
      "Total params: 1,489,012\n",
      "Trainable params: 1,489,012\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 2.52\n",
      "Params size (MB): 5.68\n",
      "Estimated Total Size (MB): 8.23\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_z = torch.zeros((64, 100)).float().to(device)\n",
    "test_label = torch.zeros((64, )).long().to(device)\n",
    "\n",
    "g = summary(G, test_z, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [x for x in range(10)]\n",
    "test_nums = []\n",
    "for i in range(10):\n",
    "    test_nums += nums\n",
    "plot_label = torch.tensor(test_nums, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  0|300]    Loss [D:0.888586 | G:4.341885]    [D(x)  0.768724| D(G(z)) 0.313065]\n",
      "Epoch [  1|300]    Loss [D:0.646186 | G:2.259886]    [D(x)  0.794189| D(G(z)) 0.271692]\n",
      "Epoch [  2|300]    Loss [D:1.424973 | G:1.352285]    [D(x)  0.659766| D(G(z)) 0.476129]\n",
      "Epoch [  3|300]    Loss [D:0.389826 | G:3.052036]    [D(x)  0.859110| D(G(z)) 0.133281]\n",
      "Epoch [  4|300]    Loss [D:0.592101 | G:3.861074]    [D(x)  0.836838| D(G(z)) 0.159907]\n",
      "Epoch [  5|300]    Loss [D:0.408857 | G:3.372977]    [D(x)  0.920338| D(G(z)) 0.188821]\n",
      "Epoch [  6|300]    Loss [D:0.548974 | G:2.095549]    [D(x)  0.820913| D(G(z)) 0.187172]\n",
      "Epoch [  7|300]    Loss [D:0.464964 | G:3.210588]    [D(x)  0.823882| D(G(z)) 0.100206]\n",
      "Epoch [  8|300]    Loss [D:0.564093 | G:2.994282]    [D(x)  0.801958| D(G(z)) 0.156918]\n",
      "Epoch [  9|300]    Loss [D:0.314814 | G:2.752543]    [D(x)  0.910845| D(G(z)) 0.149070]\n",
      "Epoch [ 10|300]    Loss [D:0.473872 | G:2.564707]    [D(x)  0.823627| D(G(z)) 0.147454]\n",
      "Epoch [ 11|300]    Loss [D:0.604388 | G:2.559359]    [D(x)  0.859082| D(G(z)) 0.242180]\n",
      "Epoch [ 12|300]    Loss [D:0.708737 | G:2.340005]    [D(x)  0.868509| D(G(z)) 0.322450]\n",
      "Epoch [ 13|300]    Loss [D:0.854372 | G:1.594174]    [D(x)  0.798257| D(G(z)) 0.336647]\n",
      "Epoch [ 14|300]    Loss [D:0.692184 | G:2.602528]    [D(x)  0.817256| D(G(z)) 0.287694]\n",
      "Epoch [ 15|300]    Loss [D:0.680751 | G:1.880644]    [D(x)  0.763871| D(G(z)) 0.223305]\n",
      "Epoch [ 16|300]    Loss [D:0.775503 | G:2.078611]    [D(x)  0.730062| D(G(z)) 0.239199]\n",
      "Epoch [ 17|300]    Loss [D:0.877267 | G:1.603984]    [D(x)  0.685460| D(G(z)) 0.260786]\n",
      "Epoch [ 18|300]    Loss [D:0.754978 | G:2.155826]    [D(x)  0.776195| D(G(z)) 0.259477]\n",
      "Epoch [ 19|300]    Loss [D:0.605754 | G:1.670999]    [D(x)  0.815129| D(G(z)) 0.244063]\n",
      "Epoch [ 20|300]    Loss [D:0.745284 | G:1.520710]    [D(x)  0.777007| D(G(z)) 0.297825]\n",
      "Epoch [ 21|300]    Loss [D:0.930677 | G:1.515718]    [D(x)  0.742297| D(G(z)) 0.344578]\n",
      "Epoch [ 22|300]    Loss [D:1.160545 | G:1.104277]    [D(x)  0.614832| D(G(z)) 0.357179]\n",
      "Epoch [ 23|300]    Loss [D:1.050339 | G:1.423569]    [D(x)  0.661582| D(G(z)) 0.278745]\n",
      "Epoch [ 24|300]    Loss [D:0.935379 | G:1.683360]    [D(x)  0.735029| D(G(z)) 0.346138]\n",
      "Epoch [ 25|300]    Loss [D:0.874637 | G:1.380679]    [D(x)  0.700336| D(G(z)) 0.310128]\n",
      "Epoch [ 26|300]    Loss [D:0.962449 | G:1.341177]    [D(x)  0.714864| D(G(z)) 0.358712]\n",
      "Epoch [ 27|300]    Loss [D:0.959492 | G:1.328809]    [D(x)  0.691048| D(G(z)) 0.346533]\n",
      "Epoch [ 28|300]    Loss [D:1.061234 | G:1.222757]    [D(x)  0.689724| D(G(z)) 0.374766]\n",
      "Epoch [ 29|300]    Loss [D:0.996721 | G:1.518570]    [D(x)  0.637364| D(G(z)) 0.325303]\n",
      "Epoch [ 30|300]    Loss [D:1.071128 | G:1.254535]    [D(x)  0.648948| D(G(z)) 0.378755]\n",
      "Epoch [ 31|300]    Loss [D:1.133478 | G:1.469581]    [D(x)  0.552612| D(G(z)) 0.300637]\n",
      "Epoch [ 32|300]    Loss [D:1.072001 | G:1.333032]    [D(x)  0.595397| D(G(z)) 0.299253]\n",
      "Epoch [ 33|300]    Loss [D:1.006963 | G:1.150662]    [D(x)  0.667527| D(G(z)) 0.361356]\n",
      "Epoch [ 34|300]    Loss [D:1.125743 | G:1.055195]    [D(x)  0.594557| D(G(z)) 0.377820]\n",
      "Epoch [ 35|300]    Loss [D:1.157047 | G:1.088694]    [D(x)  0.695848| D(G(z)) 0.458615]\n",
      "Epoch [ 36|300]    Loss [D:1.157372 | G:0.994258]    [D(x)  0.649874| D(G(z)) 0.430646]\n",
      "Epoch [ 37|300]    Loss [D:1.231851 | G:1.097600]    [D(x)  0.614141| D(G(z)) 0.421687]\n",
      "Epoch [ 38|300]    Loss [D:1.219654 | G:0.846659]    [D(x)  0.649550| D(G(z)) 0.494264]\n",
      "Epoch [ 39|300]    Loss [D:1.053543 | G:1.100239]    [D(x)  0.596459| D(G(z)) 0.349819]\n",
      "Epoch [ 40|300]    Loss [D:1.205349 | G:0.956451]    [D(x)  0.625805| D(G(z)) 0.440749]\n",
      "Epoch [ 41|300]    Loss [D:1.038931 | G:1.322440]    [D(x)  0.696794| D(G(z)) 0.405796]\n",
      "Epoch [ 42|300]    Loss [D:1.138975 | G:0.875505]    [D(x)  0.663928| D(G(z)) 0.460742]\n",
      "Epoch [ 43|300]    Loss [D:0.988507 | G:1.092234]    [D(x)  0.675917| D(G(z)) 0.373142]\n",
      "Epoch [ 44|300]    Loss [D:1.134289 | G:1.048984]    [D(x)  0.592121| D(G(z)) 0.392250]\n",
      "Epoch [ 45|300]    Loss [D:1.085125 | G:1.007981]    [D(x)  0.654948| D(G(z)) 0.396559]\n",
      "Epoch [ 46|300]    Loss [D:1.218631 | G:1.076253]    [D(x)  0.546357| D(G(z)) 0.387732]\n",
      "Epoch [ 47|300]    Loss [D:1.092118 | G:1.159324]    [D(x)  0.605878| D(G(z)) 0.375064]\n",
      "Epoch [ 48|300]    Loss [D:1.216793 | G:0.918722]    [D(x)  0.577504| D(G(z)) 0.428079]\n",
      "Epoch [ 49|300]    Loss [D:1.193651 | G:0.922015]    [D(x)  0.566214| D(G(z)) 0.387778]\n",
      "Epoch [ 50|300]    Loss [D:1.189348 | G:1.121943]    [D(x)  0.547196| D(G(z)) 0.364112]\n",
      "Epoch [ 51|300]    Loss [D:1.203151 | G:1.088692]    [D(x)  0.568007| D(G(z)) 0.396390]\n",
      "Epoch [ 52|300]    Loss [D:1.169197 | G:1.019091]    [D(x)  0.605653| D(G(z)) 0.415858]\n",
      "Epoch [ 53|300]    Loss [D:1.337938 | G:1.120835]    [D(x)  0.507150| D(G(z)) 0.364536]\n",
      "Epoch [ 54|300]    Loss [D:1.220420 | G:1.073894]    [D(x)  0.551262| D(G(z)) 0.401154]\n",
      "Epoch [ 55|300]    Loss [D:1.124842 | G:1.428084]    [D(x)  0.562959| D(G(z)) 0.306041]\n",
      "Epoch [ 56|300]    Loss [D:1.158164 | G:0.941425]    [D(x)  0.611620| D(G(z)) 0.436750]\n",
      "Epoch [ 57|300]    Loss [D:1.173153 | G:0.986536]    [D(x)  0.547362| D(G(z)) 0.386095]\n",
      "Epoch [ 58|300]    Loss [D:1.226641 | G:0.952135]    [D(x)  0.554953| D(G(z)) 0.430413]\n",
      "Epoch [ 59|300]    Loss [D:1.184330 | G:0.964994]    [D(x)  0.548876| D(G(z)) 0.392169]\n",
      "Epoch [ 60|300]    Loss [D:1.146651 | G:1.082257]    [D(x)  0.584844| D(G(z)) 0.405326]\n",
      "Epoch [ 61|300]    Loss [D:1.196383 | G:1.030251]    [D(x)  0.562501| D(G(z)) 0.393546]\n",
      "Epoch [ 62|300]    Loss [D:1.224205 | G:0.958361]    [D(x)  0.553122| D(G(z)) 0.410565]\n",
      "Epoch [ 63|300]    Loss [D:1.290483 | G:0.935810]    [D(x)  0.531337| D(G(z)) 0.431166]\n",
      "Epoch [ 64|300]    Loss [D:1.182929 | G:1.026049]    [D(x)  0.538339| D(G(z)) 0.382686]\n",
      "Epoch [ 65|300]    Loss [D:1.311224 | G:0.994718]    [D(x)  0.518201| D(G(z)) 0.417901]\n",
      "Epoch [ 66|300]    Loss [D:1.366601 | G:0.947042]    [D(x)  0.533770| D(G(z)) 0.442202]\n",
      "Epoch [ 67|300]    Loss [D:1.294108 | G:0.789767]    [D(x)  0.567295| D(G(z)) 0.476036]\n",
      "Epoch [ 68|300]    Loss [D:1.281535 | G:0.802296]    [D(x)  0.559656| D(G(z)) 0.470752]\n",
      "Epoch [ 69|300]    Loss [D:1.437976 | G:0.793147]    [D(x)  0.491944| D(G(z)) 0.455684]\n",
      "Epoch [ 70|300]    Loss [D:1.123935 | G:0.931741]    [D(x)  0.608480| D(G(z)) 0.430056]\n",
      "Epoch [ 71|300]    Loss [D:1.322541 | G:0.834690]    [D(x)  0.544028| D(G(z)) 0.456975]\n",
      "Epoch [ 72|300]    Loss [D:1.292311 | G:0.762748]    [D(x)  0.544637| D(G(z)) 0.456501]\n",
      "Epoch [ 73|300]    Loss [D:1.356235 | G:0.817812]    [D(x)  0.516454| D(G(z)) 0.465839]\n",
      "Epoch [ 74|300]    Loss [D:1.309442 | G:0.815465]    [D(x)  0.540566| D(G(z)) 0.468731]\n",
      "Epoch [ 75|300]    Loss [D:1.140424 | G:1.003362]    [D(x)  0.600899| D(G(z)) 0.406437]\n",
      "Epoch [ 76|300]    Loss [D:1.317486 | G:0.845479]    [D(x)  0.554269| D(G(z)) 0.460582]\n",
      "Epoch [ 77|300]    Loss [D:1.274271 | G:1.032624]    [D(x)  0.501385| D(G(z)) 0.344404]\n",
      "Epoch [ 78|300]    Loss [D:1.266643 | G:0.957105]    [D(x)  0.573005| D(G(z)) 0.424281]\n",
      "Epoch [ 79|300]    Loss [D:1.236561 | G:0.855341]    [D(x)  0.557018| D(G(z)) 0.446604]\n",
      "Epoch [ 80|300]    Loss [D:1.227664 | G:0.791727]    [D(x)  0.586923| D(G(z)) 0.469394]\n",
      "Epoch [ 81|300]    Loss [D:1.244318 | G:0.855680]    [D(x)  0.542963| D(G(z)) 0.441903]\n",
      "Epoch [ 82|300]    Loss [D:1.243860 | G:0.881465]    [D(x)  0.538936| D(G(z)) 0.430575]\n",
      "Epoch [ 83|300]    Loss [D:1.239461 | G:0.971168]    [D(x)  0.551422| D(G(z)) 0.435037]\n",
      "Epoch [ 84|300]    Loss [D:1.295031 | G:1.035898]    [D(x)  0.481969| D(G(z)) 0.383941]\n",
      "Epoch [ 85|300]    Loss [D:1.287464 | G:0.775814]    [D(x)  0.547771| D(G(z)) 0.476614]\n",
      "Epoch [ 86|300]    Loss [D:1.260746 | G:0.902578]    [D(x)  0.531503| D(G(z)) 0.433500]\n",
      "Epoch [ 87|300]    Loss [D:1.422975 | G:0.968320]    [D(x)  0.475897| D(G(z)) 0.433914]\n",
      "Epoch [ 88|300]    Loss [D:1.273372 | G:0.805446]    [D(x)  0.561479| D(G(z)) 0.462129]\n",
      "Epoch [ 89|300]    Loss [D:1.214598 | G:0.980871]    [D(x)  0.567492| D(G(z)) 0.425039]\n",
      "Epoch [ 90|300]    Loss [D:1.266014 | G:0.827487]    [D(x)  0.559614| D(G(z)) 0.462786]\n",
      "Epoch [ 91|300]    Loss [D:1.259025 | G:0.894790]    [D(x)  0.608335| D(G(z)) 0.459659]\n",
      "Epoch [ 92|300]    Loss [D:1.329713 | G:0.791198]    [D(x)  0.539356| D(G(z)) 0.476707]\n",
      "Epoch [ 93|300]    Loss [D:1.344172 | G:0.874593]    [D(x)  0.538720| D(G(z)) 0.452899]\n",
      "Epoch [ 94|300]    Loss [D:1.322743 | G:0.792585]    [D(x)  0.535061| D(G(z)) 0.442860]\n",
      "Epoch [ 95|300]    Loss [D:1.249722 | G:0.817652]    [D(x)  0.604213| D(G(z)) 0.476552]\n",
      "Epoch [ 96|300]    Loss [D:1.338598 | G:0.877790]    [D(x)  0.522193| D(G(z)) 0.453409]\n",
      "Epoch [ 97|300]    Loss [D:1.241697 | G:0.779461]    [D(x)  0.549845| D(G(z)) 0.454444]\n",
      "Epoch [ 98|300]    Loss [D:1.335153 | G:0.760533]    [D(x)  0.518317| D(G(z)) 0.471040]\n",
      "Epoch [ 99|300]    Loss [D:1.388654 | G:0.801361]    [D(x)  0.521363| D(G(z)) 0.479746]\n",
      "Epoch [100|300]    Loss [D:1.254317 | G:0.931956]    [D(x)  0.576974| D(G(z)) 0.440483]\n",
      "Epoch [101|300]    Loss [D:1.245807 | G:0.945542]    [D(x)  0.532317| D(G(z)) 0.408907]\n",
      "Epoch [102|300]    Loss [D:1.401818 | G:0.735678]    [D(x)  0.520335| D(G(z)) 0.502694]\n",
      "Epoch [103|300]    Loss [D:1.322747 | G:0.789473]    [D(x)  0.531527| D(G(z)) 0.465599]\n",
      "Epoch [104|300]    Loss [D:1.240233 | G:0.900068]    [D(x)  0.561647| D(G(z)) 0.433572]\n",
      "Epoch [105|300]    Loss [D:1.324507 | G:0.814421]    [D(x)  0.544770| D(G(z)) 0.477970]\n",
      "Epoch [106|300]    Loss [D:1.331320 | G:0.911846]    [D(x)  0.511015| D(G(z)) 0.414840]\n",
      "Epoch [107|300]    Loss [D:1.287842 | G:0.911892]    [D(x)  0.526607| D(G(z)) 0.431379]\n",
      "Epoch [108|300]    Loss [D:1.393425 | G:0.774995]    [D(x)  0.485178| D(G(z)) 0.448813]\n",
      "Epoch [109|300]    Loss [D:1.244987 | G:0.903208]    [D(x)  0.548528| D(G(z)) 0.422360]\n",
      "Epoch [110|300]    Loss [D:1.269755 | G:0.898757]    [D(x)  0.540475| D(G(z)) 0.435433]\n",
      "Epoch [111|300]    Loss [D:1.283917 | G:0.838163]    [D(x)  0.547141| D(G(z)) 0.451994]\n",
      "Epoch [112|300]    Loss [D:1.208575 | G:0.903981]    [D(x)  0.538367| D(G(z)) 0.401151]\n",
      "Epoch [113|300]    Loss [D:1.383889 | G:0.813649]    [D(x)  0.522141| D(G(z)) 0.476877]\n",
      "Epoch [114|300]    Loss [D:1.352345 | G:0.784638]    [D(x)  0.525916| D(G(z)) 0.470068]\n",
      "Epoch [115|300]    Loss [D:1.195619 | G:0.811317]    [D(x)  0.610173| D(G(z)) 0.460430]\n",
      "Epoch [116|300]    Loss [D:1.188018 | G:0.897951]    [D(x)  0.568733| D(G(z)) 0.430550]\n",
      "Epoch [117|300]    Loss [D:1.284138 | G:0.996347]    [D(x)  0.538811| D(G(z)) 0.410324]\n",
      "Epoch [118|300]    Loss [D:1.288880 | G:0.927384]    [D(x)  0.553780| D(G(z)) 0.435903]\n",
      "Epoch [119|300]    Loss [D:1.223341 | G:0.999102]    [D(x)  0.568039| D(G(z)) 0.436083]\n",
      "Epoch [120|300]    Loss [D:1.328349 | G:0.897326]    [D(x)  0.541887| D(G(z)) 0.460978]\n",
      "Epoch [121|300]    Loss [D:1.330891 | G:0.805431]    [D(x)  0.539208| D(G(z)) 0.474771]\n",
      "Epoch [122|300]    Loss [D:1.218168 | G:0.880119]    [D(x)  0.541842| D(G(z)) 0.426066]\n",
      "Epoch [123|300]    Loss [D:1.330356 | G:0.905988]    [D(x)  0.560854| D(G(z)) 0.467326]\n",
      "Epoch [124|300]    Loss [D:1.233714 | G:0.844485]    [D(x)  0.555734| D(G(z)) 0.444248]\n",
      "Epoch [125|300]    Loss [D:1.338494 | G:0.777686]    [D(x)  0.550310| D(G(z)) 0.492549]\n",
      "Epoch [126|300]    Loss [D:1.314663 | G:0.893050]    [D(x)  0.513246| D(G(z)) 0.431336]\n",
      "Epoch [127|300]    Loss [D:1.174837 | G:0.925021]    [D(x)  0.569873| D(G(z)) 0.421787]\n",
      "Epoch [128|300]    Loss [D:1.298266 | G:0.818776]    [D(x)  0.533769| D(G(z)) 0.455645]\n",
      "Epoch [129|300]    Loss [D:1.191955 | G:0.899300]    [D(x)  0.603994| D(G(z)) 0.434052]\n",
      "Epoch [130|300]    Loss [D:1.442936 | G:0.902441]    [D(x)  0.526181| D(G(z)) 0.459947]\n",
      "Epoch [131|300]    Loss [D:1.278188 | G:0.910744]    [D(x)  0.524240| D(G(z)) 0.434641]\n",
      "Epoch [132|300]    Loss [D:1.322032 | G:0.898180]    [D(x)  0.532378| D(G(z)) 0.466178]\n",
      "Epoch [133|300]    Loss [D:1.306683 | G:0.808628]    [D(x)  0.628397| D(G(z)) 0.509805]\n",
      "Epoch [134|300]    Loss [D:1.368566 | G:0.772759]    [D(x)  0.520855| D(G(z)) 0.480078]\n",
      "Epoch [135|300]    Loss [D:1.264399 | G:0.994199]    [D(x)  0.516664| D(G(z)) 0.398650]\n",
      "Epoch [136|300]    Loss [D:1.310472 | G:1.010643]    [D(x)  0.499346| D(G(z)) 0.390506]\n",
      "Epoch [137|300]    Loss [D:1.176082 | G:0.910389]    [D(x)  0.574609| D(G(z)) 0.434342]\n",
      "Epoch [138|300]    Loss [D:1.370357 | G:0.779373]    [D(x)  0.535282| D(G(z)) 0.484791]\n",
      "Epoch [139|300]    Loss [D:1.286024 | G:0.914215]    [D(x)  0.544301| D(G(z)) 0.435880]\n",
      "Epoch [140|300]    Loss [D:1.480653 | G:0.801594]    [D(x)  0.460226| D(G(z)) 0.465498]\n",
      "Epoch [141|300]    Loss [D:1.369888 | G:0.803631]    [D(x)  0.533292| D(G(z)) 0.478339]\n",
      "Epoch [142|300]    Loss [D:1.333390 | G:0.739383]    [D(x)  0.568256| D(G(z)) 0.501613]\n",
      "Epoch [143|300]    Loss [D:1.416354 | G:0.776588]    [D(x)  0.508706| D(G(z)) 0.494079]\n",
      "Epoch [144|300]    Loss [D:1.401822 | G:1.000401]    [D(x)  0.535367| D(G(z)) 0.478188]\n",
      "Epoch [145|300]    Loss [D:1.427197 | G:0.791751]    [D(x)  0.537624| D(G(z)) 0.508124]\n",
      "Epoch [146|300]    Loss [D:1.310426 | G:0.802005]    [D(x)  0.528135| D(G(z)) 0.459832]\n",
      "Epoch [147|300]    Loss [D:1.412523 | G:0.818301]    [D(x)  0.513619| D(G(z)) 0.471404]\n",
      "Epoch [148|300]    Loss [D:1.262424 | G:0.839022]    [D(x)  0.542770| D(G(z)) 0.445114]\n",
      "Epoch [149|300]    Loss [D:1.290858 | G:0.826410]    [D(x)  0.561107| D(G(z)) 0.471118]\n",
      "Epoch [150|300]    Loss [D:1.324194 | G:0.718055]    [D(x)  0.542272| D(G(z)) 0.492005]\n",
      "Epoch [151|300]    Loss [D:1.266484 | G:0.767904]    [D(x)  0.543098| D(G(z)) 0.464801]\n",
      "Epoch [152|300]    Loss [D:1.334763 | G:0.911644]    [D(x)  0.529334| D(G(z)) 0.454486]\n",
      "Epoch [153|300]    Loss [D:1.232883 | G:0.922069]    [D(x)  0.545391| D(G(z)) 0.420590]\n",
      "Epoch [154|300]    Loss [D:1.267548 | G:0.791223]    [D(x)  0.541235| D(G(z)) 0.457607]\n",
      "Epoch [155|300]    Loss [D:1.215505 | G:0.923272]    [D(x)  0.535152| D(G(z)) 0.409885]\n",
      "Epoch [156|300]    Loss [D:1.332257 | G:0.804561]    [D(x)  0.537432| D(G(z)) 0.469691]\n",
      "Epoch [157|300]    Loss [D:1.308687 | G:0.824456]    [D(x)  0.553530| D(G(z)) 0.469498]\n",
      "Epoch [158|300]    Loss [D:1.261982 | G:0.959135]    [D(x)  0.538052| D(G(z)) 0.427494]\n",
      "Epoch [159|300]    Loss [D:1.377003 | G:0.772367]    [D(x)  0.539742| D(G(z)) 0.502898]\n",
      "Epoch [160|300]    Loss [D:1.212622 | G:0.831247]    [D(x)  0.585482| D(G(z)) 0.455185]\n",
      "Epoch [161|300]    Loss [D:1.485734 | G:0.752611]    [D(x)  0.477154| D(G(z)) 0.503051]\n",
      "Epoch [162|300]    Loss [D:1.347529 | G:0.754374]    [D(x)  0.522037| D(G(z)) 0.486870]\n",
      "Epoch [163|300]    Loss [D:1.342046 | G:0.813561]    [D(x)  0.560134| D(G(z)) 0.483448]\n",
      "Epoch [164|300]    Loss [D:1.288262 | G:0.791007]    [D(x)  0.534696| D(G(z)) 0.466213]\n",
      "Epoch [165|300]    Loss [D:1.288206 | G:0.923996]    [D(x)  0.549386| D(G(z)) 0.437941]\n",
      "Epoch [166|300]    Loss [D:1.399591 | G:0.765143]    [D(x)  0.541566| D(G(z)) 0.494709]\n",
      "Epoch [167|300]    Loss [D:1.339370 | G:0.799507]    [D(x)  0.528300| D(G(z)) 0.474038]\n",
      "Epoch [168|300]    Loss [D:1.258314 | G:0.771396]    [D(x)  0.601954| D(G(z)) 0.495564]\n",
      "Epoch [169|300]    Loss [D:1.364250 | G:0.782770]    [D(x)  0.532628| D(G(z)) 0.496593]\n",
      "Epoch [170|300]    Loss [D:1.239481 | G:0.859581]    [D(x)  0.588207| D(G(z)) 0.453035]\n",
      "Epoch [171|300]    Loss [D:1.358571 | G:0.769267]    [D(x)  0.525843| D(G(z)) 0.485142]\n",
      "Epoch [172|300]    Loss [D:1.474417 | G:0.740774]    [D(x)  0.504752| D(G(z)) 0.511538]\n",
      "Epoch [173|300]    Loss [D:1.202042 | G:0.954215]    [D(x)  0.583961| D(G(z)) 0.434820]\n",
      "Epoch [174|300]    Loss [D:1.338845 | G:0.906643]    [D(x)  0.517147| D(G(z)) 0.435922]\n",
      "Epoch [175|300]    Loss [D:1.317595 | G:0.851856]    [D(x)  0.537248| D(G(z)) 0.453463]\n",
      "Epoch [176|300]    Loss [D:1.204234 | G:0.922026]    [D(x)  0.565239| D(G(z)) 0.427287]\n",
      "Epoch [177|300]    Loss [D:1.330236 | G:0.739253]    [D(x)  0.520891| D(G(z)) 0.477110]\n",
      "Epoch [178|300]    Loss [D:1.373458 | G:0.804758]    [D(x)  0.517392| D(G(z)) 0.464748]\n",
      "Epoch [179|300]    Loss [D:1.287054 | G:0.890924]    [D(x)  0.552244| D(G(z)) 0.432300]\n",
      "Epoch [180|300]    Loss [D:1.267167 | G:0.787736]    [D(x)  0.550432| D(G(z)) 0.471588]\n",
      "Epoch [181|300]    Loss [D:1.340124 | G:0.858563]    [D(x)  0.511332| D(G(z)) 0.461599]\n",
      "Epoch [182|300]    Loss [D:1.345150 | G:0.868722]    [D(x)  0.542614| D(G(z)) 0.473642]\n",
      "Epoch [183|300]    Loss [D:1.409516 | G:0.747983]    [D(x)  0.543467| D(G(z)) 0.505453]\n",
      "Epoch [184|300]    Loss [D:1.345208 | G:0.776441]    [D(x)  0.557388| D(G(z)) 0.501869]\n",
      "Epoch [185|300]    Loss [D:1.396775 | G:0.786418]    [D(x)  0.558371| D(G(z)) 0.505570]\n",
      "Epoch [186|300]    Loss [D:1.356786 | G:0.934495]    [D(x)  0.492385| D(G(z)) 0.442576]\n",
      "Epoch [187|300]    Loss [D:1.321113 | G:0.873048]    [D(x)  0.532294| D(G(z)) 0.450053]\n",
      "Epoch [188|300]    Loss [D:1.361269 | G:0.751229]    [D(x)  0.520569| D(G(z)) 0.486976]\n",
      "Epoch [189|300]    Loss [D:1.243004 | G:0.878863]    [D(x)  0.558103| D(G(z)) 0.442823]\n",
      "Epoch [190|300]    Loss [D:1.289450 | G:0.813579]    [D(x)  0.528186| D(G(z)) 0.463296]\n",
      "Epoch [191|300]    Loss [D:1.267117 | G:0.797542]    [D(x)  0.566248| D(G(z)) 0.473659]\n",
      "Epoch [192|300]    Loss [D:1.395623 | G:0.688646]    [D(x)  0.526093| D(G(z)) 0.511342]\n",
      "Epoch [193|300]    Loss [D:1.363974 | G:0.771766]    [D(x)  0.527287| D(G(z)) 0.487911]\n",
      "Epoch [194|300]    Loss [D:1.367569 | G:0.628162]    [D(x)  0.551322| D(G(z)) 0.527357]\n",
      "Epoch [195|300]    Loss [D:1.307914 | G:0.788784]    [D(x)  0.544133| D(G(z)) 0.466927]\n",
      "Epoch [196|300]    Loss [D:1.265523 | G:0.806821]    [D(x)  0.557657| D(G(z)) 0.460481]\n",
      "Epoch [197|300]    Loss [D:1.341610 | G:0.727555]    [D(x)  0.511599| D(G(z)) 0.474451]\n",
      "Epoch [198|300]    Loss [D:1.293803 | G:0.897424]    [D(x)  0.538087| D(G(z)) 0.436020]\n",
      "Epoch [199|300]    Loss [D:1.284148 | G:0.780655]    [D(x)  0.557505| D(G(z)) 0.476920]\n",
      "Epoch [200|300]    Loss [D:1.341517 | G:0.835277]    [D(x)  0.507940| D(G(z)) 0.446446]\n",
      "Epoch [201|300]    Loss [D:1.303442 | G:0.781993]    [D(x)  0.538227| D(G(z)) 0.478742]\n",
      "Epoch [202|300]    Loss [D:1.325235 | G:0.827752]    [D(x)  0.559046| D(G(z)) 0.470150]\n",
      "Epoch [203|300]    Loss [D:1.400417 | G:0.819180]    [D(x)  0.523011| D(G(z)) 0.491635]\n",
      "Epoch [204|300]    Loss [D:1.324706 | G:0.882301]    [D(x)  0.550518| D(G(z)) 0.464619]\n",
      "Epoch [205|300]    Loss [D:1.332268 | G:0.755286]    [D(x)  0.532418| D(G(z)) 0.486547]\n",
      "Epoch [206|300]    Loss [D:1.213176 | G:0.872633]    [D(x)  0.562183| D(G(z)) 0.442606]\n",
      "Epoch [207|300]    Loss [D:1.326047 | G:0.843298]    [D(x)  0.531757| D(G(z)) 0.465615]\n",
      "Epoch [208|300]    Loss [D:1.376719 | G:0.746739]    [D(x)  0.531479| D(G(z)) 0.494786]\n",
      "Epoch [209|300]    Loss [D:1.327772 | G:0.958202]    [D(x)  0.555785| D(G(z)) 0.467644]\n",
      "Epoch [210|300]    Loss [D:1.322233 | G:0.904525]    [D(x)  0.515951| D(G(z)) 0.440653]\n",
      "Epoch [211|300]    Loss [D:1.354347 | G:0.814193]    [D(x)  0.545771| D(G(z)) 0.493868]\n",
      "Epoch [212|300]    Loss [D:1.346491 | G:0.785646]    [D(x)  0.519484| D(G(z)) 0.479181]\n",
      "Epoch [213|300]    Loss [D:1.412631 | G:0.697271]    [D(x)  0.537725| D(G(z)) 0.529217]\n",
      "Epoch [214|300]    Loss [D:1.300832 | G:0.848631]    [D(x)  0.523871| D(G(z)) 0.448641]\n",
      "Epoch [215|300]    Loss [D:1.318933 | G:0.792444]    [D(x)  0.506518| D(G(z)) 0.454434]\n",
      "Epoch [216|300]    Loss [D:1.407636 | G:0.750010]    [D(x)  0.538521| D(G(z)) 0.513955]\n",
      "Epoch [217|300]    Loss [D:1.316782 | G:0.814881]    [D(x)  0.556360| D(G(z)) 0.483370]\n",
      "Epoch [218|300]    Loss [D:1.359417 | G:0.956959]    [D(x)  0.492918| D(G(z)) 0.420215]\n",
      "Epoch [219|300]    Loss [D:1.346093 | G:0.742859]    [D(x)  0.524785| D(G(z)) 0.480819]\n",
      "Epoch [220|300]    Loss [D:1.332379 | G:0.772344]    [D(x)  0.533432| D(G(z)) 0.476884]\n",
      "Epoch [221|300]    Loss [D:1.350495 | G:0.735384]    [D(x)  0.521325| D(G(z)) 0.485724]\n",
      "Epoch [222|300]    Loss [D:1.332181 | G:0.909893]    [D(x)  0.505101| D(G(z)) 0.410134]\n",
      "Epoch [223|300]    Loss [D:1.328590 | G:0.716517]    [D(x)  0.532338| D(G(z)) 0.487979]\n",
      "Epoch [224|300]    Loss [D:1.394747 | G:0.840800]    [D(x)  0.516935| D(G(z)) 0.470207]\n",
      "Epoch [225|300]    Loss [D:1.351823 | G:0.799824]    [D(x)  0.509134| D(G(z)) 0.459751]\n",
      "Epoch [226|300]    Loss [D:1.300138 | G:0.764404]    [D(x)  0.528098| D(G(z)) 0.472238]\n",
      "Epoch [227|300]    Loss [D:1.276813 | G:0.755092]    [D(x)  0.528541| D(G(z)) 0.455359]\n",
      "Epoch [228|300]    Loss [D:1.338209 | G:0.821596]    [D(x)  0.544888| D(G(z)) 0.468931]\n",
      "Epoch [229|300]    Loss [D:1.388989 | G:0.831839]    [D(x)  0.510671| D(G(z)) 0.486275]\n",
      "Epoch [230|300]    Loss [D:1.343408 | G:0.767123]    [D(x)  0.517293| D(G(z)) 0.477998]\n",
      "Epoch [231|300]    Loss [D:1.390684 | G:0.809621]    [D(x)  0.508603| D(G(z)) 0.474092]\n",
      "Epoch [232|300]    Loss [D:1.313044 | G:0.781990]    [D(x)  0.523732| D(G(z)) 0.467465]\n",
      "Epoch [233|300]    Loss [D:1.367071 | G:0.785505]    [D(x)  0.530219| D(G(z)) 0.485788]\n",
      "Epoch [234|300]    Loss [D:1.349681 | G:0.805577]    [D(x)  0.539310| D(G(z)) 0.487035]\n",
      "Epoch [235|300]    Loss [D:1.247579 | G:0.862697]    [D(x)  0.546323| D(G(z)) 0.434177]\n",
      "Epoch [236|300]    Loss [D:1.387790 | G:0.773980]    [D(x)  0.502709| D(G(z)) 0.485950]\n",
      "Epoch [237|300]    Loss [D:1.301687 | G:0.825634]    [D(x)  0.540329| D(G(z)) 0.466197]\n",
      "Epoch [238|300]    Loss [D:1.341783 | G:0.734680]    [D(x)  0.526029| D(G(z)) 0.478320]\n",
      "Epoch [239|300]    Loss [D:1.329384 | G:0.754962]    [D(x)  0.525919| D(G(z)) 0.469074]\n",
      "Epoch [240|300]    Loss [D:1.364291 | G:0.785012]    [D(x)  0.533610| D(G(z)) 0.477032]\n",
      "Epoch [241|300]    Loss [D:1.386158 | G:0.735384]    [D(x)  0.543168| D(G(z)) 0.505321]\n",
      "Epoch [242|300]    Loss [D:1.301586 | G:0.814999]    [D(x)  0.532243| D(G(z)) 0.446711]\n",
      "Epoch [243|300]    Loss [D:1.327399 | G:0.776740]    [D(x)  0.546151| D(G(z)) 0.487088]\n",
      "Epoch [244|300]    Loss [D:1.356257 | G:0.813523]    [D(x)  0.507154| D(G(z)) 0.463022]\n",
      "Epoch [245|300]    Loss [D:1.304645 | G:0.830604]    [D(x)  0.541833| D(G(z)) 0.466918]\n",
      "Epoch [246|300]    Loss [D:1.416436 | G:0.810577]    [D(x)  0.511590| D(G(z)) 0.482510]\n",
      "Epoch [247|300]    Loss [D:1.282800 | G:0.908417]    [D(x)  0.546193| D(G(z)) 0.453083]\n",
      "Epoch [248|300]    Loss [D:1.285237 | G:0.828256]    [D(x)  0.548937| D(G(z)) 0.462026]\n",
      "Epoch [249|300]    Loss [D:1.384805 | G:0.700801]    [D(x)  0.537400| D(G(z)) 0.511851]\n",
      "Epoch [250|300]    Loss [D:1.377307 | G:0.737908]    [D(x)  0.526959| D(G(z)) 0.496063]\n",
      "Epoch [251|300]    Loss [D:1.326329 | G:0.791911]    [D(x)  0.545087| D(G(z)) 0.491263]\n",
      "Epoch [252|300]    Loss [D:1.301663 | G:0.747989]    [D(x)  0.542457| D(G(z)) 0.478088]\n",
      "Epoch [253|300]    Loss [D:1.303403 | G:0.841771]    [D(x)  0.530246| D(G(z)) 0.468050]\n",
      "Epoch [254|300]    Loss [D:1.316869 | G:0.803695]    [D(x)  0.532037| D(G(z)) 0.469626]\n",
      "Epoch [255|300]    Loss [D:1.273556 | G:0.852677]    [D(x)  0.530396| D(G(z)) 0.449009]\n",
      "Epoch [256|300]    Loss [D:1.296491 | G:0.885015]    [D(x)  0.585688| D(G(z)) 0.476447]\n",
      "Epoch [257|300]    Loss [D:1.393543 | G:0.733953]    [D(x)  0.517989| D(G(z)) 0.494830]\n",
      "Epoch [258|300]    Loss [D:1.342615 | G:0.736800]    [D(x)  0.519868| D(G(z)) 0.480856]\n",
      "Epoch [259|300]    Loss [D:1.294930 | G:0.742834]    [D(x)  0.560513| D(G(z)) 0.482407]\n",
      "Epoch [260|300]    Loss [D:1.319848 | G:0.742923]    [D(x)  0.542153| D(G(z)) 0.484152]\n",
      "Epoch [261|300]    Loss [D:1.353771 | G:0.724447]    [D(x)  0.541313| D(G(z)) 0.506009]\n",
      "Epoch [262|300]    Loss [D:1.287895 | G:0.928976]    [D(x)  0.540239| D(G(z)) 0.440724]\n",
      "Epoch [263|300]    Loss [D:1.409760 | G:0.758764]    [D(x)  0.530568| D(G(z)) 0.499203]\n",
      "Epoch [264|300]    Loss [D:1.227066 | G:0.831827]    [D(x)  0.552514| D(G(z)) 0.438948]\n",
      "Epoch [265|300]    Loss [D:1.347785 | G:0.771098]    [D(x)  0.526039| D(G(z)) 0.482149]\n",
      "Epoch [266|300]    Loss [D:1.296917 | G:0.823914]    [D(x)  0.533997| D(G(z)) 0.454993]\n",
      "Epoch [267|300]    Loss [D:1.306659 | G:0.879529]    [D(x)  0.508791| D(G(z)) 0.450584]\n",
      "Epoch [268|300]    Loss [D:1.280396 | G:0.932226]    [D(x)  0.527800| D(G(z)) 0.437443]\n",
      "Epoch [269|300]    Loss [D:1.337552 | G:0.731073]    [D(x)  0.537656| D(G(z)) 0.486846]\n",
      "Epoch [270|300]    Loss [D:1.359916 | G:0.729424]    [D(x)  0.531661| D(G(z)) 0.492760]\n",
      "Epoch [271|300]    Loss [D:1.354923 | G:0.721396]    [D(x)  0.525158| D(G(z)) 0.488403]\n",
      "Epoch [272|300]    Loss [D:1.380663 | G:0.807512]    [D(x)  0.499812| D(G(z)) 0.455590]\n",
      "Epoch [273|300]    Loss [D:1.318783 | G:0.822432]    [D(x)  0.542101| D(G(z)) 0.471946]\n",
      "Epoch [274|300]    Loss [D:1.282836 | G:0.883647]    [D(x)  0.526608| D(G(z)) 0.444869]\n",
      "Epoch [275|300]    Loss [D:1.363851 | G:0.774998]    [D(x)  0.537017| D(G(z)) 0.493485]\n",
      "Epoch [276|300]    Loss [D:1.379539 | G:0.800045]    [D(x)  0.515439| D(G(z)) 0.483107]\n",
      "Epoch [277|300]    Loss [D:1.344928 | G:0.845898]    [D(x)  0.525495| D(G(z)) 0.458137]\n",
      "Epoch [278|300]    Loss [D:1.306396 | G:0.817577]    [D(x)  0.524033| D(G(z)) 0.460158]\n",
      "Epoch [279|300]    Loss [D:1.269157 | G:0.823125]    [D(x)  0.534473| D(G(z)) 0.446266]\n",
      "Epoch [280|300]    Loss [D:1.309067 | G:0.770461]    [D(x)  0.535851| D(G(z)) 0.469230]\n",
      "Epoch [281|300]    Loss [D:1.457776 | G:0.768722]    [D(x)  0.486227| D(G(z)) 0.480777]\n",
      "Epoch [282|300]    Loss [D:1.309036 | G:0.778944]    [D(x)  0.524579| D(G(z)) 0.463935]\n",
      "Epoch [283|300]    Loss [D:1.318001 | G:0.860385]    [D(x)  0.504504| D(G(z)) 0.438661]\n",
      "Epoch [284|300]    Loss [D:1.340393 | G:0.749412]    [D(x)  0.516712| D(G(z)) 0.466999]\n",
      "Epoch [285|300]    Loss [D:1.329626 | G:0.754246]    [D(x)  0.549110| D(G(z)) 0.494316]\n",
      "Epoch [286|300]    Loss [D:1.308211 | G:0.777491]    [D(x)  0.528989| D(G(z)) 0.469749]\n",
      "Epoch [287|300]    Loss [D:1.294827 | G:0.767056]    [D(x)  0.533862| D(G(z)) 0.465157]\n",
      "Epoch [288|300]    Loss [D:1.342347 | G:0.817932]    [D(x)  0.514565| D(G(z)) 0.469522]\n",
      "Epoch [289|300]    Loss [D:1.368459 | G:0.785334]    [D(x)  0.542396| D(G(z)) 0.492353]\n",
      "Epoch [290|300]    Loss [D:1.350366 | G:0.829217]    [D(x)  0.506507| D(G(z)) 0.449447]\n",
      "Epoch [291|300]    Loss [D:1.357891 | G:0.842303]    [D(x)  0.512289| D(G(z)) 0.462091]\n",
      "Epoch [292|300]    Loss [D:1.299758 | G:0.794994]    [D(x)  0.533695| D(G(z)) 0.472487]\n",
      "Epoch [293|300]    Loss [D:1.345598 | G:0.764392]    [D(x)  0.522313| D(G(z)) 0.481933]\n",
      "Epoch [294|300]    Loss [D:1.343966 | G:0.806234]    [D(x)  0.512372| D(G(z)) 0.459957]\n",
      "Epoch [295|300]    Loss [D:1.335380 | G:0.775342]    [D(x)  0.521062| D(G(z)) 0.461148]\n",
      "Epoch [296|300]    Loss [D:1.350032 | G:0.814829]    [D(x)  0.514468| D(G(z)) 0.451566]\n",
      "Epoch [297|300]    Loss [D:1.268921 | G:0.792389]    [D(x)  0.554921| D(G(z)) 0.463523]\n",
      "Epoch [298|300]    Loss [D:1.344481 | G:0.765805]    [D(x)  0.512289| D(G(z)) 0.478488]\n",
      "Epoch [299|300]    Loss [D:1.282814 | G:0.742661]    [D(x)  0.558701| D(G(z)) 0.477892]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_step = len(data_loader)\n",
    "for epoch in range(EPOCHS+1):\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        images = images.reshape(BATCH_SIZE, -1).to(device)\n",
    "        \n",
    "        real_labels = torch.ones(BATCH_SIZE, 1).to(device)\n",
    "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(device)\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        outputs = D(images, labels)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        z = torch.randn(BATCH_SIZE, 100).to(device)\n",
    "        g_label = torch.randint(0, 10, (BATCH_SIZE, )).to(device)\n",
    "        fake_image = G(z, g_label)\n",
    "        \n",
    "        outputs = D(fake_image, g_label)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        d_optim.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optim.step()\n",
    "        \n",
    "        fake_images = G(z, g_label)\n",
    "        otuptus = D(fake_images, g_label)\n",
    "        g_loss = criterion(otuptus, real_labels)\n",
    "        \n",
    "        g_optim.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optim.step()  \n",
    "    print(\"Epoch [{:3d}|{:3d}]    Loss [D:{:8.6f} | G:{:8.6f}]    [D(x)  {:8.6f}| D(G(z)) {:8.6f}]\".format(\n",
    "        epoch, EPOCHS, d_loss.item(), g_loss.item(), real_score.mean().item(), fake_score.mean().item()\n",
    "    ))\n",
    "    \n",
    "    if epoch % 30 == 0:\n",
    "        z = torch.randn(100, 100).to(device)\n",
    "        sample_imgs = G(z, plot_label)\n",
    "        sample_imgs = sample_imgs.reshape((100, 1, 28, 28))\n",
    "        sample_imgs = torchvision.utils.make_grid(sample_imgs, nrow=10)\n",
    "        plot_imgs   = np.clip(sample_imgs.data.cpu().numpy().transpose(1, 2, 0), 0, 1)\n",
    "\n",
    "        plt.imshow(plot_imgs)\n",
    "        plt.title(\"Epoch [{:3d}/{:3d}]\".format(epoch, EPOCHS))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.savefig(\"./results/Epoch_{:3d}.png\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G.state_dict(), \"./models/generator.ptr\")\n",
    "torch.save(D.state_dict(), \"./models/discriminator.ptr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
